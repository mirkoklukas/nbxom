{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tags, filter cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#default_exp om2\n",
    "import re\n",
    "regex_tag = re.compile(r\"^\\s*#([a-zA-Z_]+).*$\")\n",
    "\n",
    "def extract_tag(line):\n",
    "    \"\"\"Returns the name of a tag (#name), if it \n",
    "    occurs at the beginning of the line, or None.\"\"\"\n",
    "    m = regex_tag.match(line)\n",
    "    if m is not None: return m.group(1)\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extract_tag(\"#nbx \") == \"nbx\"\n",
    "assert extract_tag(\"#nbx  something else \") == \"nbx\"\n",
    "assert extract_tag(\"# nbx something else \") == None\n",
    "assert extract_tag(\"#xarg \") == \"xarg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def contains_tag(name):\n",
    "    return lambda line: extract_tag(line) == name\n",
    "\n",
    "is_nbx = contains_tag(\"nbx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_nbx(\"#nbx\") \n",
    "assert is_nbx(\"# nbx\") == False\n",
    "assert is_nbx(\" #nbx\") \n",
    "assert is_nbx(\"  #nbx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def is_nbx_cell(cell):\n",
    "    if cell['cell_type'] != 'code': return False\n",
    "    if not cell['source']: return False\n",
    "    line0 = cell['source'][0]\n",
    "    return is_nbx(line0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "regex_magic =  re.compile(r\"^\\s*%{1,2}|^\\s*!\")\n",
    "\n",
    "def is_magic_or_shell(line):\n",
    "    \"\"\"Checks if line contains a jupyter \n",
    "    magic function or shell command\"\"\"\n",
    "    m = regex_magic.match(line)\n",
    "    return m is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_magic_or_shell(\"%pwd \")\n",
    "assert is_magic_or_shell(\"%%capture \")\n",
    "assert is_magic_or_shell(\"!ls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing \"xargs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to parse the line below `#xarg`, and decompose it into a variable declaration and the parameter range for the sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "regex_xarg = re.compile(r\"\"\"\n",
    "^\n",
    "([^=]+)\n",
    "=\n",
    "([^;]+)\n",
    ";?\n",
    "(.*)\n",
    "$\"\"\", re.VERBOSE)\n",
    "\n",
    "def strip(s):\n",
    "    return s.strip()\n",
    "\n",
    "def parse_xarg_expr(line):\n",
    "    \"\"\"Parses the line below an `xarg` tag, e.g.\n",
    "        ('x', '0', '[1,2,3,4]') = parse_xarg_expr(\"x = 0; [1,2,3,4]\")  \n",
    "    \"\"\"\n",
    "    m = regex_xarg.match(line)\n",
    "    name, val, sweep = map(strip, m.groups())\n",
    "    return name, val, sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('x', 'f(a)', '[f(1),f(a),6,8]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_xarg_expr(\"x = f(a) ; [f(1),f(a),6,8]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing \"nbx\" cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "from argparse import Namespace\n",
    "\n",
    "class Bunch(object):\n",
    "    def __init__(self, adict={}):\n",
    "        self.__dict__.update(adict)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__.keys())\n",
    "\n",
    "def load_nb(fname):\n",
    "    nbdict = json.load(open(fname,'r',encoding=\"utf-8\"))\n",
    "    nb = Bunch(nbdict)\n",
    "    nb.name = fname\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cells', 'metadata', 'nbformat', 'nbformat_minor', 'name'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = load_nb(\"om2.ipynb\")\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_src_with_parse_dict(a, src, parse_dict):\n",
    "    if len(src) == 0: return a, []\n",
    "    \n",
    "    tag = extract_tag(src[0])\n",
    "    if tag is None or \\\n",
    "       tag not in parse_dict: \n",
    "            a, rest = parse_none(a, src)\n",
    "    else: \n",
    "            a, rest = parse_dict[tag](a, src)\n",
    "\n",
    "    return parse_src_with_parse_dict(a, rest, parse_dict)\n",
    "\n",
    "\n",
    "def parse_none(a, src):\n",
    "    if not is_magic_or_shell(src[0]):\n",
    "        a['none'].append(src[0])\n",
    "    rest = src[1:]\n",
    "    return a, rest\n",
    "\n",
    "def parse_nbx(a, src):\n",
    "    a[\"nbx\"].append(src[0])\n",
    "    rest = src[1:]\n",
    "    return a, rest\n",
    "\n",
    "def parse_xarg(a, src):\n",
    "    a[\"xarg\"].append(src[1])\n",
    "    rest = src[2:]\n",
    "    return a, rest\n",
    "\n",
    "def parse_xuse(a, src):\n",
    "    a[\"xuse\"].append(src[1])\n",
    "    rest = src[2:]\n",
    "    return a, rest\n",
    "\n",
    "def consume_line_below(tag, basket=None):\n",
    "    if basket is None: basket = tag\n",
    "    \n",
    "    def parse(a, src):\n",
    "        a[basket].append(src[1])\n",
    "        rest = src[2:]\n",
    "        return a, rest\n",
    "    \n",
    "    return parse\n",
    "\n",
    "\n",
    "PARSE_DICT = {\n",
    "    'xarg': consume_line_below('xarg', basket=None),\n",
    "    'ximp': consume_line_below('ximp', basket=None)\n",
    "}\n",
    "    \n",
    "def parse_nbx_cell_with_parse_dict(cell, parse_dict=PARSE_DICT):\n",
    "    a = dict([(t,[]) for t in parse_dict.keys()])\n",
    "    a['none'] = []\n",
    "    a, _ = parse_src_with_parse_dict(a, cell['source'], parse_dict)\n",
    "    \n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n",
      "** Parsed Cell **\n",
      "*****************\n",
      ">> Parsed... xarg's: ... \n",
      "x = 0 ; [0,1,2,3,4]\n",
      "y = 0 ;\n",
      "task_id = 0\n",
      "results_dir = \"./\"\n",
      ">> Parsed... ximp's: ... \n",
      "import numpy as np\n",
      "from numpy import *\n",
      ">> Parsed... none's: ... \n",
      "#nbx\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#watch\n",
      "z = 1\n",
      "*****************\n",
      "** Parsed Cell **\n",
      "*****************\n",
      ">> Parsed... xarg's: ... \n",
      ">> Parsed... ximp's: ... \n",
      ">> Parsed... none's: ... \n",
      "#nbx\n",
      "print(\"some result\")\n"
     ]
    }
   ],
   "source": [
    "nb = load_nb(\"om2.ipynb\")\n",
    "for cell in list(filter(is_nbx_cell, nb.cells)):    \n",
    "    print(\"*****************\\n** Parsed Cell **\\n*****************\")\n",
    "    a = parse_nbx_cell_with_parse_dict(cell)\n",
    "    for key, vals in a.items():\n",
    "        print(f\">> Parsed... {key}'s: ... \")\n",
    "        [print(v.strip()) for v in vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "#ximp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#ximp\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "#xarg \n",
    "x = 0 ; [0,1,2,3,4]  \n",
    "    \n",
    "#xarg \n",
    "y = 0 ;\n",
    "\n",
    "#xarg\n",
    "task_id = 0\n",
    "#xarg\n",
    "results_dir = \"./\"\n",
    "\n",
    "#watch\n",
    "z = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some result\n"
     ]
    }
   ],
   "source": [
    "#nbx\n",
    "print(\"some result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import reduce\n",
    "\n",
    "def concat(list1, list2):\n",
    "    return list1 + list2\n",
    "\n",
    "def unzip(zipped):\n",
    "    return zip(*zipped)\n",
    "\n",
    "def negate(func):\n",
    "    return lambda x: not func(x)\n",
    "\n",
    "def is_constarg(a):\n",
    "    return len(a[2]) == 0\n",
    "\n",
    "not_constarg = negate(is_constarg)\n",
    "\n",
    "def get_item(i):\n",
    "    return lambda x: x[i]\n",
    "\n",
    "def get_items(*I):\n",
    "    return lambda x: tuple([x[i] for i in I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_nb_with_parse_dict(nb, parse_dict=PARSE_DICT):\n",
    "    nbx_cells = filter(is_nbx_cell, nb.cells)\n",
    "\n",
    "    keys = parse_dict\n",
    "    A = dict([(k,[]) for k in parse_dict.keys()])\n",
    "    A['func_body'] = []\n",
    "    for cell in nbx_cells:\n",
    "        a = parse_nbx_cell_with_parse_dict(cell, parse_dict)\n",
    "        \n",
    "        for k in parse_dict.keys():\n",
    "            A[k].extend(a[k])\n",
    "        A['func_body'].extend(a['none'])\n",
    "    \n",
    "    A['xarg'] = [parse_xarg_expr(line) for line in A['xarg']]\n",
    "    A['args'] = list(map(get_items(0,1), A['xarg']))\n",
    "    A['const_args'] = list(map(get_items(0,1), filter(is_constarg, A['xarg'])))\n",
    "    A['sweep_args'] = list(map(get_items(0,2), filter(not_constarg, A['xarg'])))\n",
    "    A['name'] = nb.name\n",
    "\n",
    "         \n",
    "    return A\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xarg': [('x', '0', '[0,1,2,3,4]'),\n",
       "  ('y', '0', ''),\n",
       "  ('task_id', '0', ''),\n",
       "  ('results_dir', '\"./\"', '')],\n",
       " 'ximp': ['import numpy as np\\n', 'from numpy import *\\n'],\n",
       " 'func_body': ['#nbx\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  '    \\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  '#watch\\n',\n",
       "  'z = 1',\n",
       "  '#nbx\\n',\n",
       "  'print(\"some result\")'],\n",
       " 'args': [('x', '0'), ('y', '0'), ('task_id', '0'), ('results_dir', '\"./\"')],\n",
       " 'const_args': [('y', '0'), ('task_id', '0'), ('results_dir', '\"./\"')],\n",
       " 'sweep_args': [('x', '[0,1,2,3,4]')],\n",
       " 'name': 'om2.ipynb'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = load_nb(\"om2.ipynb\")\n",
    "nb = parse_nb_with_parse_dict(nb, parse_dict=PARSE_DICT)\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the file bundle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_arrays(num, m=1000):\n",
    "    if num < m: return [[1,num]]\n",
    "    \n",
    "    arrays = []\n",
    "    for i in range(num//m): arrays.append([i*m+1, (i+1)*m])\n",
    "    last = arrays[-1][1]\n",
    "    if last < num: arrays.append([last+1, num])\n",
    "        \n",
    "    return arrays\n",
    "\n",
    "def get_arrays_2(num, m=1000):\n",
    "    if num < m: return [[1,num]]\n",
    "    \n",
    "    arrays = []\n",
    "    for i in range(num//m): arrays.append([1, m])\n",
    "    last = arrays[-1][1]\n",
    "    if num%m!=0: arrays.append([1,num%m])\n",
    "        \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1000], [1001, 1543]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1000], [1, 543]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_arrays(1543, 1000))\n",
    "get_arrays_2(1543, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_job(start, end, step):\n",
    "    return f\"job_0=`sbatch --array={start}-{end}%{step} job_0.sh | awk '{{ print $4 }}'`\"\n",
    "\n",
    "def cont_job(j, start, end, step):\n",
    "    return f\"job_{j}=`sbatch --array={start}-{end}%{step} --dependency=afterok:$job_{j-1} job_{j}.sh | awk '{{ print $4 }}'`\"\n",
    "\n",
    "def chain_jobs(arrays, step):\n",
    "    s = \"\"\n",
    "    for i, arr in enumerate(arrays):\n",
    "        if i ==0: s += init_job(arr[0], arr[1], step)\n",
    "        else: s += cont_job(i, arr[0], arr[1], step)\n",
    "        s += \"\\n\"  \n",
    "    return s\n",
    "\n",
    "def chain_jobs_2(arrays, step):\n",
    "    s = \"\"\n",
    "    for i, arr in enumerate(arrays):\n",
    "        if i ==0: s += init_job(arr[0], arr[1], step)\n",
    "        else: s += cont_job(i, arr[0], arr[1], step)\n",
    "        s += \"\\n\"  \n",
    "    return s    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_0=`sbatch --array=1-1000%10 job_0.sh | awk '{ print $4 }'`\n",
      "job_1=`sbatch --array=1-1000%10 --dependency=afterok:$job_0 job_1.sh | awk '{ print $4 }'`\n",
      "job_2=`sbatch --array=1-543%10 --dependency=afterok:$job_1 job_2.sh | awk '{ print $4 }'`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chain_jobs_2(get_arrays_2(2543, 1000), step=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundle functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import PurePosixPath as Path\n",
    "import pkg_resources\n",
    "import importlib\n",
    "from nbx.templ import *\n",
    "import os\n",
    "\n",
    "def add_if_necessary(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = v\n",
    "    \n",
    "    \n",
    "def create_script(tpath, tname, fname, vars):\n",
    "    print(f\"Creating... {fname} \\n\\tfrom {tname}\")\n",
    "    create_file_from_template(tpath/tname, fname, vars)\n",
    "    \n",
    "\n",
    "tpath = Path(pkg_resources.resource_filename(__name__, \"templates/\"))\n",
    "\n",
    "\n",
    "def create_om_files(target_dir,  lang, num_jobs, simg, job_header, experiment=\"experiment.py\",\n",
    "                    arr_size=900, step=100, tpath=tpath, copy_folders=[\"data\", \"src\"], job_abbr=\"nbxjob\", bind=[], sym=[]):\n",
    "    \"\"\"\n",
    "    Creates a bundle folder and all the scripts \n",
    "    needed to run an experiment script on OM...\n",
    "    \n",
    "    Example usage:\n",
    "    \n",
    "    >> create_om_files(  \n",
    "            target_dir = \"EXAMPLE_BUNDLE\", \n",
    "            lang = \"py\", \n",
    "            num_jobs = 10,\n",
    "            simg = \"pytorch.simg\",\n",
    "            job_header = {\n",
    "                \"time\": \"01:20:00\",\n",
    "                \"partition\": \"fiete\",\n",
    "                \"mem\": \"32gb\",\n",
    "                \"cpus-per-task\": 4,\n",
    "                \"mail-user\": \"me@somewhere.com\"})\n",
    "                \n",
    "    >> create_experiment_script(\n",
    "            nbname = \"my_notebook.ipynb\",\n",
    "            target_dir = \"./_EXAMPLE_BUNDLE\", \n",
    "            lang = \"py\")\n",
    "            \n",
    "    \"\"\"\n",
    "    print(f\"Creating om ... files...\\n\\tfrom {tpath}\")\n",
    "\n",
    "    \n",
    "    create_folders(target_dir, lang, copy_folders=copy_folders)\n",
    "    create_run_and_job_script(target_dir, lang, simg, job_header, num_jobs, \n",
    "                              arr_size, step,  tpath=tpath, job_abbr=job_abbr, bind=bind, sym=sym, experiment=experiment)\n",
    "#     create_job_script(target_dir, lang, simg, job_header)\n",
    "    \n",
    "    print(render_template_from_string(INSTRUCTIONS, {\"path\": target_dir, \"lang\": lang}))\n",
    "    \n",
    "    \n",
    "INSTRUCTIONS = \"\"\"\n",
    "** Instructions: **\n",
    "    Copy to remote, run, and pull the results:\n",
    "    - `!scp -r {{path}} $om:$omx`\n",
    "   (- `!scp -r {{path}}/experiment.{{lang}} $om:$omx/experiment.{{lang}}`)\n",
    "    - `!ssh $om sbatch -D $omx/{{path}} $omx/{{path}}/run.sh`\n",
    "    - `!scp -r $om:$omx/{{path}}/results/* ./results`\n",
    "    \n",
    "    For this to work you have to set a few environment variables...\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_folders(path, lang, copy_folders):\n",
    "    path=Path(path)\n",
    "            \n",
    "    \n",
    "    for p in [path, path/'io', path/'results']:\n",
    "        if not os.path.exists(p): os.makedirs(p)\n",
    "\n",
    "    for folder in copy_folders:\n",
    "        if os.path.exists(f\"./{folder}\"):\n",
    "            if not os.path.exists(path/folder):\n",
    "                os.makedirs(path/folder)\n",
    "            os.system(f\"cp -r {folder}/* {path/folder}\") \n",
    "                  \n",
    "\n",
    "    \n",
    "    if lang==\".py\":\n",
    "        open(path/'__init__.py', 'a').close()\n",
    "                           \n",
    "\n",
    "def create_run_and_job_script(target_dir, lang, simg, job_header, \n",
    "                              num_jobs, arr_size, step,  tpath=tpath, \n",
    "                              job_abbr=\"nbxjob\", bind=[], sym=[], experiment=\"experiment.py\"):\n",
    "    assert arr_size <= 1000, \"Maximum number of queued jobs on OM is 1000\"   \n",
    "    fname = Path(target_dir)/'run.sh'\n",
    "    \n",
    "    job_arrays = get_arrays_2(num_jobs, arr_size)\n",
    "    \n",
    "    # Run script         \n",
    "    tname = \"run_sh.tpl\"\n",
    "    fname = Path(target_dir)/f\"run.sh\"\n",
    "    create_script(tpath, tname, fname, {\n",
    "        'specs_array': [[j]+job_arrays[j]+[j*arr_size] \n",
    "                             for j in range(len(job_arrays))],\n",
    "        'job_name': f\"{job_abbr}\",\n",
    "        'step': step\n",
    "    })    \n",
    "        \n",
    "    # Jobs\n",
    "    create_job_script(target_dir, lang, simg, job_header, tpath, bind, sym, experiment)\n",
    "#     for j,arr in enumerate(job_arrays):\n",
    "#         task_offset = j*arr_size\n",
    "#         create_job_script(target_dir, lang, simg, j, job_header, task_offset, tpath)\n",
    "        \n",
    "        \n",
    "\n",
    "def create_job_script(target_dir, lang, simg, job_header, tpath, bind=[], sym=[], experiment=\"experiment.py\"):\n",
    "    \n",
    "    simg        = Path(os.environ['omsimg'])/simg\n",
    "    nbx_folder  = Path(os.environ['omx'])\n",
    "    results_dir = Path(\"./results\")\n",
    "    \n",
    "    print(f\"\\nNBX folder: {nbx_folder}\\n\")\n",
    "    \n",
    "    add_if_necessary(job_header, \"out\", \"io/out_%a\")\n",
    "    add_if_necessary(job_header, \"error\", \"io/err_%a\")\n",
    "    add_if_necessary(job_header, \"mail-type\", \"END\")\n",
    "    add_if_necessary(job_header, \"exclude\", \"node030,node016,node015\")\n",
    "    \n",
    "    tname = f\"job_{lang}.tpl\"\n",
    "    fname = Path(target_dir)/f\"job.sh\"\n",
    "    create_script(tpath, tname, fname, {\n",
    "        'job_header': job_header.items(),\n",
    "        'nbx_folder': nbx_folder,\n",
    "        'bind': bind,\n",
    "        'simg': simg,\n",
    "        'symlinks': sym,\n",
    "        'results_dir': results_dir,\n",
    "        'experiment': experiment\n",
    "    })       \n",
    "\n",
    "    \n",
    "def check_nb(pnb):\n",
    "    keys = list(map(get_item(0), pnb['args']))\n",
    "    if \"task_id\" not in keys: raise KeyError(\"You didn't specify `task_id`!!\")\n",
    "    if \"results_dir\" not in keys: raise KeyError(\"You didn't specify `results_dir`!!\")\n",
    "    \n",
    "                  \n",
    "def create_experiment_script(nbname, target_dir=\".\", lang=\"py\", tpath=tpath):\n",
    "    print(\"** Creating Experiment script and folder **\")\n",
    "    nb = load_nb(nbname)\n",
    "    nb = parse_nb_with_parse_dict(nb, parse_dict=PARSE_DICT)\n",
    "    check_nb(nb)\n",
    "                  \n",
    "    path=Path(target_dir)\n",
    "            \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    tname = f\"experiment_{lang}.tpl\"                  \n",
    "    fname = path/f\"experiment.{lang}\"\n",
    "    create_script(tpath, tname, fname, nb)    \n",
    "\n",
    "                  \n",
    "    if lang == \"py\":\n",
    "        open(path/'__init__.py', 'a').close()                  \n",
    "        exp = \".\".join((path/'experiment').parts)\n",
    "        m =  importlib.import_module(exp)\n",
    "        num_params = len(m.sweep_params)\n",
    "                  \n",
    "    print(f\"Number of params: {num_params}\")\n",
    "                  \n",
    "    return {\"num_jobs\": num_params, \"target_dir\": target_dir, \"lang\": lang}\n",
    "                   \n",
    "    \n",
    "def create_raw_experiment(fname=\"experiment.py\", lang=\"py\", tpath=tpath):\n",
    "    print(\"** Creating Raw Experiment**\")\n",
    "                  \n",
    "    tname = f\"experiment_raw_{lang}.tpl\"                  \n",
    "    fname = Path(fname)\n",
    "    \n",
    "    create_script(tpath, tname, fname, {})    \n",
    "\n",
    "                \n",
    "                   \n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurePosixPath('templates')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating om ... files...\n",
      "\tfrom /Users/mirko/Workspace/nbx/nbx/templates\n",
      "Creating... OM2_EXAMPLE/run.sh \n",
      "\tfrom run_sh.tpl\n",
      "\n",
      "NBX folder: /om2/user/mklukas/nbx-experiments\n",
      "\n",
      "Creating... OM2_EXAMPLE/job.sh \n",
      "\tfrom job_py.tpl\n",
      "\n",
      "** Instructions: **\n",
      "    Copy to remote, run, and pull the results:\n",
      "    - `!scp -r OM2_EXAMPLE $om:$omx`\n",
      "   (- `!scp -r OM2_EXAMPLE/experiment.py $om:$omx/experiment.py`)\n",
      "    - `!ssh $om sbatch -D $omx/OM2_EXAMPLE $omx/OM2_EXAMPLE/run.sh`\n",
      "    - `!scp -r $om:$omx/OM2_EXAMPLE/results/* ./results`\n",
      "    \n",
      "    For this to work you have to set a few environment variables...\n",
      "    \n"
     ]
    }
   ],
   "source": [
    " create_om_files(target_dir=\"OM2_EXAMPLE\", lang=\"py\", \n",
    "                 num_jobs=3453, \n",
    "                 arr_size=500, step=17, \n",
    "                 simg=\"pytorch.simg\", \n",
    "                 bind=[],\n",
    "                 job_header={\n",
    "                    \"time\": \"10:00:00\",\n",
    "                    \"partition\": \"fiete\",\n",
    "                    \"mail-user\": \"me@somewhere.com\"}, \n",
    "                 tpath=Path(\"/Users/mirko/Workspace/nbx/nbx/templates\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Creating Experiment script and folder **\n",
      "Creating... OM2_EXAMPLE/experiment.py \n",
      "\tfrom experiment_py.tpl\n",
      "Number of params: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_jobs': 5, 'target_dir': 'OM2_EXAMPLE', 'lang': 'py'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_experiment_script(\"om2.ipynb\", target_dir=\"OM2_EXAMPLE\", lang=\"py\", tpath=Path(\"/Users/mirko/Workspace/nbx/nbx/templates\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
