{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tags, filter cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#default_exp om2\n",
    "import re\n",
    "_re_tag = re.compile(r\"^\\s*#([a-zA-Z_]+).*$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_tag(line):\n",
    "    \"\"\"Returns the name of a tag (#name), if it \n",
    "    occurs at the beginning of the line, or None.\"\"\"\n",
    "    m = _re_tag.match(line)\n",
    "    if m is not None: return m.group(1)\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extract_tag(\"#nbx \") == \"nbx\"\n",
    "assert extract_tag(\"#nbx  something else \") == \"nbx\"\n",
    "assert extract_tag(\"# nbx something else \") == None\n",
    "assert extract_tag(\"#xarg \") == \"xarg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def contains_tag(name):\n",
    "    return lambda line: extract_tag(line) == name\n",
    "\n",
    "is_nbx = contains_tag(\"nbx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_nbx(\"#nbx\") \n",
    "assert is_nbx(\"# nbx\") == False\n",
    "assert is_nbx(\" #nbx\") \n",
    "assert is_nbx(\"  #nbx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def is_nbx_cell(cell):\n",
    "    if cell['cell_type'] != 'code': return False\n",
    "    if not cell['source']: return False\n",
    "    line0 = cell['source'][0]\n",
    "    return is_nbx(line0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create our python script we need to exclude jupyter's *magic* functions and shell commands that can beused in a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_magic =  re.compile(r\"^\\s*%{1,2}|^\\s*!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_magic_or_shell(line):\n",
    "    m = _re_magic.match(line)\n",
    "    return m is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_magic_or_shell(\"%pwd \")\n",
    "assert is_magic_or_shell(\"%%capture \")\n",
    "assert is_magic_or_shell(\"!ls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing \"xargs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to parse the line below `#xarg`, and decompose it into a variable declaration and the parameter range for the sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                \n",
    "_re_xarg = re.compile(r\"\"\"\n",
    "# parses the line below an `xarg` tag:\n",
    "^\n",
    "([^=]+)\n",
    "=\n",
    "([^;]+)\n",
    ";?\n",
    "(.*)\n",
    "$\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def strip(s):\n",
    "    return s.strip()\n",
    "\n",
    "def parse_xarg_expr(line):\n",
    "    m = _re_xarg.match(line)\n",
    "    name, val, sweep = map(strip, m.groups())\n",
    "    return name, val, sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('x', 'f(a)', '[f(1),f(a),6,8]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_xarg_expr(\"x = f(a) ; [f(1),f(a),6,8]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing \"nbx\" cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "from argparse import Namespace\n",
    "\n",
    "class Bunch(object):\n",
    "    def __init__(self, adict={}):\n",
    "        self.__dict__.update(adict)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__.keys())\n",
    "\n",
    "def load_nb(fname):\n",
    "    nbdict = json.load(open(fname,'r',encoding=\"utf-8\"))\n",
    "    nb = Bunch(nbdict)\n",
    "    nb.name = fname\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cells', 'metadata', 'nbformat', 'nbformat_minor', 'name'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = load_nb(\"om.ipynb\")\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_src_with_parse_dict(a, src, parse_dict):\n",
    "    if len(src) == 0: return a, []\n",
    "    \n",
    "    tag = extract_tag(src[0])\n",
    "    if tag is None or tag not in parse_dict: a, rest = parse_none(a, src)\n",
    "    else: a, rest = parse_dict[tag](a, src)\n",
    "\n",
    "    return parse_src_with_parse_dict(a, rest, parse_dict)\n",
    "\n",
    "\n",
    "def parse_none(a, src):\n",
    "    if not is_magic_or_shell(src[0]):\n",
    "        a['none'].append(src[0])\n",
    "    rest = src[1:]\n",
    "    return a, rest\n",
    "\n",
    "\n",
    "def parse_nbx(a, src):\n",
    "    a[\"nbx\"].append(src[0])\n",
    "    rest = src[1:]\n",
    "    return a, rest\n",
    "\n",
    "def parse_xarg(a, src):\n",
    "    a[\"xarg\"].append(src[1])\n",
    "    rest = src[2:]\n",
    "    return a, rest\n",
    "\n",
    "def parse_xuse(a, src):\n",
    "    a[\"xuse\"].append(src[1])\n",
    "    rest = src[2:]\n",
    "    return a, rest\n",
    "\n",
    "\n",
    "PARSE_DICT = {\n",
    "    'xarg': parse_xarg,\n",
    "    'xuse': parse_xuse}\n",
    "    \n",
    "def parse_nbx_cell_with_parse_dict(cell, parse_dict=PARSE_DICT):\n",
    "    a = dict([(t,[]) for t in parse_dict.keys()])\n",
    "    a['none'] = []\n",
    "    \n",
    "    a, _ = parse_src_with_parse_dict(a, cell['source'], parse_dict)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************\n",
      "** Parsed Cell **\n",
      "*****************\n",
      "\n",
      "----------\n",
      "   xarg   \n",
      "----------\n",
      "x = 0 ; [0,1,2,3,4]\n",
      "y = 0 ;\n",
      "task_id = 0\n",
      "results_dir = \"./\"\n",
      "----------\n",
      "   xuse   \n",
      "----------\n",
      "----------\n",
      "   none   \n",
      "----------\n",
      "#nbx\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# some comment\n",
      "z = 1\n",
      "*****************\n",
      "** Parsed Cell **\n",
      "*****************\n",
      "\n",
      "----------\n",
      "   xarg   \n",
      "----------\n",
      "----------\n",
      "   xuse   \n",
      "----------\n",
      "----------\n",
      "   none   \n",
      "----------\n",
      "#nbx\n",
      "\n",
      "print(\"some result\")"
     ]
    }
   ],
   "source": [
    "nb = load_nb(\"om.ipynb\")\n",
    "for cell in list(filter(is_nbx_cell, nb.cells)):    \n",
    "    print(\"\\n*****************\\n** Parsed Cell **\\n*****************\\n\")\n",
    "    a = parse_nbx_cell_with_parse_dict(cell)\n",
    "    for key, vals in a.items():\n",
    "        print(f\"--{'-'*len(key)}----\\n   {key}   \\n--{'-'*len(key)}----\")\n",
    "        [print(v, end=\"\") for v in vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "\n",
    "#xarg \n",
    "x = 0 ; [0,1,2,3,4]\n",
    "\n",
    "#xarg \n",
    "y = 0 ;\n",
    "\n",
    "#xarg\n",
    "task_id = 0\n",
    "#xarg\n",
    "results_dir = \"./\"\n",
    "\n",
    "# some comment\n",
    "z = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some result\n"
     ]
    }
   ],
   "source": [
    "#nbx\n",
    "\n",
    "print(\"some result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import reduce\n",
    "\n",
    "def concat(list1, list2):\n",
    "    return list1 + list2\n",
    "\n",
    "def unzip(zipped):\n",
    "    return zip(*zipped)\n",
    "\n",
    "def negate(func):\n",
    "    return lambda x: not func(x)\n",
    "\n",
    "def is_constarg(a):\n",
    "    return len(a[2]) == 0\n",
    "\n",
    "not_constarg = negate(is_constarg)\n",
    "\n",
    "def get_item(i):\n",
    "    return lambda x: x[i]\n",
    "\n",
    "def get_items(*I):\n",
    "    return lambda x: tuple([x[i] for i in I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def parse_nb_with_parse_dict(nb, parse_dict=PARSE_DICT):\n",
    "    nbx_cells = filter(is_nbx_cell, nb.cells)\n",
    "\n",
    "    keys = parse_dict\n",
    "    A = dict([(k,[]) for k in parse_dict.keys()])\n",
    "    A['func_body'] = []\n",
    "    for cell in nbx_cells:\n",
    "        a = parse_nbx_cell_with_parse_dict(cell, parse_dict)\n",
    "        \n",
    "        for k in parse_dict.keys():\n",
    "            A[k].extend(a[k])\n",
    "        A['func_body'].extend(a['none'])\n",
    "    \n",
    "    A['xarg'] = [parse_xarg_expr(line) for line in A['xarg']]\n",
    "    A['args'] = list(map(get_items(0,1), A['xarg']))\n",
    "    A['const_args'] = list(map(get_items(0,1), filter(is_constarg, A['xarg'])))\n",
    "    A['sweep_args'] = list(map(get_items(0,2), filter(not_constarg, A['xarg'])))\n",
    "    A['name'] = nb.name\n",
    "\n",
    "         \n",
    "    return A\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xarg': [('x', '0', '[0,1,2,3,4]'),\n",
       "  ('y', '0', ''),\n",
       "  ('task_id', '0', ''),\n",
       "  ('results_dir', '\"./\"', '')],\n",
       " 'xuse': [],\n",
       " 'func_body': ['#nbx\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  '# some comment\\n',\n",
       "  'z = 1',\n",
       "  '#nbx\\n',\n",
       "  '\\n',\n",
       "  'print(\"some result\")'],\n",
       " 'args': [('x', '0'), ('y', '0'), ('task_id', '0'), ('results_dir', '\"./\"')],\n",
       " 'const_args': [('y', '0'), ('task_id', '0'), ('results_dir', '\"./\"')],\n",
       " 'sweep_args': [('x', '[0,1,2,3,4]')],\n",
       " 'name': 'om.ipynb'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = load_nb(\"om.ipynb\")\n",
    "nb = parse_nb_with_parse_dict(nb, parse_dict=PARSE_DICT)\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the file bundle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_arrays(num, m=1000):\n",
    "    if num < m: return [[1,num]]\n",
    "    \n",
    "    arrays = []\n",
    "    for i in range(num//m): arrays.append([i*m+1, (i+1)*m])\n",
    "    last = arrays[-1][1]\n",
    "    if last < num: arrays.append([last+1, num])\n",
    "        \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1000], [1001, 1543]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_arrays(1543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_job(start, end, step):\n",
    "    return f\"job_0=`sbatch --array={start}-{end}%{step} job.sh | awk '{{ print $4 }}'`\"\n",
    "def cont_job(j, start, end, step):\n",
    "    return f\"job_{j}=`sbatch --array={start}-{end}%{step} --dependency=afterok:$job_{j-1} job.sh | awk '{{ print $4 }}'`\"\n",
    "\n",
    "def chain_jobs(arrays, step):\n",
    "    s = \"\"\n",
    "    for i, arr in enumerate(arrays):\n",
    "        if i ==0: s += init_job(arr[0], arr[1], step)\n",
    "        else: s += cont_job(i, arr[0], arr[1], step)\n",
    "        s += \"\\n\"  \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_0=`sbatch --array=1-1000%1 job.sh | awk '{ print $4 }'`\n",
      "job_1=`sbatch --array=1001-1543%1 --dependency=afterok:$job_0 job.sh | awk '{ print $4 }'`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chain_jobs(get_arrays(1543), step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundle functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_if_necessary(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = v\n",
    "    \n",
    "    \n",
    "def create_script(tpath, tname, fname, vars):\n",
    "    print(f\"Creating... {fname} \\n\\tfrom {tname}\")\n",
    "    create_file_from_template(tpath/tname, fname, vars)\n",
    "    \n",
    "\n",
    "tpath = Path(pkg_resources.resource_filename(__name__, \"templates/\"))\n",
    "\n",
    "\n",
    "def create_om_files(target_dir, lang, num_jobs, simg, job_header, arr_size=1000, step=20):\n",
    "    \"\"\"\n",
    "    Creates a bundle folder and all the scripts \n",
    "    needed to run an experiment script on OM...\n",
    "    \n",
    "    Example usage:\n",
    "    \n",
    "    >> create_om_files(  \n",
    "            target_dir = \"./_EXAMPLE_BUNDLE\", \n",
    "            lang = \"py\", \n",
    "            num_jobs = 10,\n",
    "            simg = \"pytorch.simg\",\n",
    "            job_header = {\n",
    "                \"--time\": \"01:20:00\",\n",
    "                \"--partition\": \"fiete\",\n",
    "                \"--mem\": \"32gb\",\n",
    "                \"--cpus-per-task\": 4,\n",
    "                \"--mail-user\": \"me@somewhere.com\"})\n",
    "                \n",
    "    >> create_experiment_script(\n",
    "            nbname = \"my_notebook.ipynb\",\n",
    "            target_dir = \"./_EXAMPLE_BUNDLE\", \n",
    "            lang = \"py\")\n",
    "            \n",
    "    \"\"\"\n",
    "    print(f\"Creating om ... files...\\n\\tfrom {tpath}\")\n",
    "    \n",
    "    create_folders(target_dir, lang)\n",
    "    create_run_script(target_dir, num_jobs, arr_size, step)\n",
    "    create_job_script(target_dir, lang, simg, job_header)\n",
    "    \n",
    "    print(render_template_from_string(INSTRUCTIONS, {\"path\": target_dir}))\n",
    "    \n",
    "    \n",
    "INSTRUCTIONS = \"\"\"\n",
    "** Instructions: **\n",
    "    Copy to remote, run, and pull the results:\n",
    "    - `!scp -r {{path}} $om:$omx` \n",
    "    - `!ssh $om sbatch -D $omx/{{path}} $omx/{{path}}/run.sh`\n",
    "    - `!scp -r $om:$omx/{{path}}/results ./results`\n",
    "    \n",
    "    For this to work you have to set a few environment variables...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_folders(path, lang):\n",
    "    path=Path(path)\n",
    "            \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        os.makedirs(path/'io')\n",
    "        os.makedirs(path/'results')\n",
    "\n",
    "    if os.path.exists('./src'):\n",
    "        if not os.path.exists(path/'src'):\n",
    "            os.makedirs(path/'src')\n",
    "        os.system(f\"cp -r src/* {path/'src'}\") \n",
    "                  \n",
    "    if os.path.exists('./data'):\n",
    "        if not os.path.exists(path/'data'):\n",
    "            os.makedirs(path/'data')\n",
    "        os.system(f\"cp -r data/* {path/'data'}\") \n",
    "    \n",
    "    if lang==\".py\":\n",
    "        open(path/'__init__.py', 'a').close()\n",
    "                           \n",
    "\n",
    "def create_run_script(target_dir, num_jobs, arr_size, step):\n",
    "    assert arr_size <= 1000, \"Maximum number of queued jobs on OM is 1000\"   \n",
    "    fname = Path(target_dir)/'run.sh'\n",
    "    with open(fname, \"w\", newline=\"\\n\") as f:\n",
    "        f.write(\"#!/bin/sh\\n\\n\")\n",
    "        f.write(\"#SBATCH --out=io/runner_out__%A\\n\")\n",
    "        f.write(\"#SBATCH --error=io/runner_err__%A\\n\\n\")\n",
    "        f.write(chain_jobs(get_arrays(num_jobs, arr_size), step))\n",
    "\n",
    "\n",
    "def create_job_script(target_dir, lang, simg, job_header):\n",
    "    \n",
    "    simg        = Path(os.environ['omsimg'])/simg\n",
    "    nbx_folder  = Path(os.environ['omx'])\n",
    "    results_dir = Path(\"./results\")\n",
    "    \n",
    "    add_if_necessary(job_header, \"--out\", \"io/out_%a\")\n",
    "    add_if_necessary(job_header, \"--error\", \"io/err_%a\")\n",
    "    add_if_necessary(job_header, \"--mail-type\", \"END\")\n",
    "    add_if_necessary(job_header, \"--exclude\", \"node030,node016,node015\")\n",
    "    \n",
    "    tname = f\"job_{lang}.tpl\"\n",
    "    fname = Path(target_dir)/'job.sh'\n",
    "    create_script(tpath, tname, fname, {\n",
    "        'job_header': job_header.items(),\n",
    "        'nbx_folder': nbx_folder,\n",
    "        'simg': simg,\n",
    "        'results_dir': results_dir\n",
    "    })       \n",
    "\n",
    "    \n",
    "def check_nb(pnb):\n",
    "    keys = list(map(get_item(0), pnb['args']))\n",
    "    if \"task_id\" not in keys: raise KeyError(\"You didn't specify `task_id`!!\")\n",
    "    if \"results_dir\" not in keys: raise KeyError(\"You didn't specify `results_dir`!!\")\n",
    "    \n",
    "                  \n",
    "def create_experiment_script(nbname, target_dir, lang=\"py\"):\n",
    "    nb = load_nb(nbname)\n",
    "    nb = parse_nb_with_parse_dict(nb, parse_dict=PARSE_DICT)\n",
    "    check_nb(nb)\n",
    "\n",
    "    tname = f\"experiment_{lang}.tpl\"                  \n",
    "    fname = Path(target_dir)/f\"experiment.{lang}\"\n",
    "    create_script(tpath, tname, fname, nb)      \n",
    "                   \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
