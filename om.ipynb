{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tags, filter cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#default_exp om\n",
    "import re\n",
    "_re_tag = re.compile(r\"^\\s*#([a-zA-Z_]+).*$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_tag(line):\n",
    "    \"\"\"Returns the name of a tag (#name), if it \n",
    "    occurs at the beginning of the line, or None.\"\"\"\n",
    "    m = _re_tag.match(line)\n",
    "    if m is not None: return m.group(1)\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extract_tag(\"#nbx \") == \"nbx\"\n",
    "assert extract_tag(\"#nbx  something else \") == \"nbx\"\n",
    "assert extract_tag(\"# nbx something else \") == None\n",
    "assert extract_tag(\"#xarg \") == \"xarg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def contains_tag(name):\n",
    "    return lambda line: extract_tag(line) == name\n",
    "\n",
    "is_nbx = contains_tag(\"nbx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_nbx(\"#nbx\") \n",
    "assert is_nbx(\"# nbx\") == False\n",
    "assert is_nbx(\" #nbx\") \n",
    "assert is_nbx(\"  #nbx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def is_nbx_cell(cell):\n",
    "    if cell['cell_type'] != 'code': return False\n",
    "    if not cell['source']: return False\n",
    "    line0 = cell['source'][0]\n",
    "    return is_nbx(line0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create our python script we need to exclude jupyter's *magic* functions and shell commands that can beused in a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_magic =  re.compile(r\"^\\s*%{1,2}|^\\s*!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_magic_or_shell(line):\n",
    "    m = _re_magic.match(line)\n",
    "    return m is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_magic_or_shell(\"%pwd \")\n",
    "assert is_magic_or_shell(\"%%capture \")\n",
    "assert is_magic_or_shell(\"!ls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing \"xargs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to parse the line below `#xarg`, and decompose it into a variable declaration and the parameter range for the sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                \n",
    "_re_xarg = re.compile(r\"\"\"\n",
    "# parses the line below an `xarg` tag:\n",
    "^\n",
    "([^=]+)\n",
    "=\n",
    "([^;]+)\n",
    ";?\n",
    "(.*)\n",
    "$\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def strip(s):\n",
    "    return s.strip()\n",
    "\n",
    "def parse_xarg(line):\n",
    "    m = _re_xarg.match(line)\n",
    "    name, val, sweep = map(strip, m.groups())\n",
    "    return name, val, sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('x', '0', '[0,1,2,3]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_xarg(\"x = 0 ; [0,1,2,3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast\n",
    "from collections import namedtuple\n",
    "\n",
    "Import = namedtuple(\"Import\", [\"module\", \"name\", \"alias\"])\n",
    "\n",
    "def get_imports_from_src(src):\n",
    "    \"\"\"Taken from:\n",
    "        https://stackoverflow.com/questions/9008451/python-easy-way-to-read-all-import-statements-from-py-module \n",
    "    \"\"\"\n",
    "    root = ast.parse(src)\n",
    "    start = None\n",
    "    end = None\n",
    "    occ = []\n",
    "    imp = []\n",
    "    stm = []\n",
    "    for node in ast.iter_child_nodes(root):\n",
    "        occ.append((node.lineno))\n",
    "\n",
    "        if isinstance(node, ast.Import):\n",
    "            imp.append(True)\n",
    "            module = []\n",
    "        elif isinstance(node, ast.ImportFrom):  \n",
    "            imp.append(True)\n",
    "            module = node.module.split('.')\n",
    "        else:\n",
    "            imp.append(False)\n",
    "            continue\n",
    "        \n",
    "        for n in node.names:\n",
    "            stm.append(Import(\".\".join(module), n.name, n.asname))\n",
    "    \n",
    "    print(occ)\n",
    "    \n",
    "    ign = []\n",
    "    lines = src.split(\"\\n\")\n",
    "    occ.append(len(lines))\n",
    "    for i in range(len(occ)-1):\n",
    "        if imp[i] == True:\n",
    "            ign.extend(range(occ[i]-1,occ[i+1]-1))\n",
    "            \n",
    "                \n",
    "    return stm, ign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_import_statement(module, name, alias):\n",
    "    if module == '':\n",
    "        return f\"import {name}\" + (\"\" if alias == None else f\" as {alias}\")\n",
    "    else:\n",
    "        return f\"from {module} import {name}\" + (\"\" if alias == None else f\" as {alias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"\"\"\n",
    "import ast\n",
    "x=0;\n",
    "from collections import (namedtuple,\n",
    "                         b)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_imports_from(src):\n",
    "    imps, ign = get_imports_from_src(src)    \n",
    "    return [create_import_statement(*im) for im in imps], ign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['import ast',\n",
       "  'from collections import namedtuple',\n",
       "  'from collections import b'],\n",
       " [1, 3, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_imports_from(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing \"nbx\" cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "from argparse import Namespace\n",
    "\n",
    "class Bunch(object):\n",
    "    def __init__(self, adict={}):\n",
    "        self.__dict__.update(adict)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__.keys())\n",
    "\n",
    "def load_nb(fname):\n",
    "    nbdict = json.load(open(fname,'r',encoding=\"utf-8\"))\n",
    "    return Bunch(nbdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cells', 'metadata', 'nbformat', 'nbformat_minor'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = load_nb(\"om.ipynb\")\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_src(a, src):\n",
    "    if len(src) == 0: return a, []\n",
    "    \n",
    "    tag = extract_tag(src[0])\n",
    "    if tag is None:\n",
    "        if not is_magic_or_shell(src[0]):\n",
    "            a['xbody'].append(src[0])\n",
    "        rest = src[1:]\n",
    "        \n",
    "    elif tag == 'nbx':   \n",
    "        a['xbody'].append(src[0])\n",
    "        rest = src[1:]\n",
    "        \n",
    "    elif tag == 'xarg':   \n",
    "        a['xarg'].append(src[1])\n",
    "        rest = src[2:]\n",
    "        \n",
    "    else:\n",
    "        rest = src[1:]\n",
    "\n",
    "    return parse_src(a, rest)\n",
    "    \n",
    "\n",
    "def parse_nbx_cell(cell):\n",
    "    a = {'xbody': [], 'xarg': [] }\n",
    "    a, _ = parse_src(a, cell['source'])\n",
    "    return a['xarg'], a['xbody']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbx\n",
    "\n",
    "#xarg \n",
    "x = 0 ; [0,1,2,3,4]\n",
    "\n",
    "#xarg \n",
    "y = 0 ;\n",
    "\n",
    "#xarg\n",
    "task_id = 0\n",
    "#xarg\n",
    "results_dir = \"./\"\n",
    "\n",
    "# some comment\n",
    "z = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some result\n"
     ]
    }
   ],
   "source": [
    "#nbx\n",
    "\n",
    "print(\"some result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************\n",
      "** Parsed Cell **\n",
      "*****************\n",
      "\n",
      "['x = 0 ; [0,1,2,3,4]\\n', 'y = 0 ;\\n', 'task_id = 0\\n', 'results_dir = \"./\"\\n']\n",
      "['#nbx\\n', '\\n', '\\n', '\\n', '\\n', '# some comment\\n', 'z = 1']\n",
      "\n",
      "*****************\n",
      "** Parsed Cell **\n",
      "*****************\n",
      "\n",
      "[]\n",
      "['#nbx\\n', '\\n', 'print(\"some result\")']\n"
     ]
    }
   ],
   "source": [
    "nb = load_nb(\"om.ipynb\")\n",
    "for cell in list(filter(is_nbx_cell, nb.cells)):    \n",
    "    print(\"\\n*****************\\n** Parsed Cell **\\n*****************\\n\")\n",
    "    xarg, xbody = parse_nbx_cell(cell)\n",
    "    print(xarg)\n",
    "    print(xbody)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import reduce\n",
    "\n",
    "def concat(list1, list2):\n",
    "    return list1 + list2\n",
    "\n",
    "def unzip(zipped):\n",
    "    return zip(*zipped)\n",
    "\n",
    "def negate(func):\n",
    "    return lambda x: not func(x)\n",
    "\n",
    "def is_constarg(a):\n",
    "    return len(a[2]) == 0\n",
    "\n",
    "not_constarg = negate(is_constarg)\n",
    "\n",
    "def get_item(i):\n",
    "    return lambda x: x[i]\n",
    "\n",
    "def get_items(*I):\n",
    "    return lambda x: tuple([x[i] for i in I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_nb(nb):\n",
    "    nbx_cells = filter(is_nbx_cell, nb.cells)\n",
    "\n",
    "    xargs = []\n",
    "    xbody = []\n",
    "    for cell in nbx_cells:\n",
    "        xa, xb = parse_nbx_cell(cell)        \n",
    "        xargs += [parse_xarg(line) for line in xa]\n",
    "        xbody += xb\n",
    "    \n",
    "    pnb = Bunch()    \n",
    "    pnb.func_body = xbody\n",
    "    pnb.args = list(map(get_items(0,1), xargs))\n",
    "    pnb.const_args = list(map(get_items(0,1), filter(is_constarg, xargs)))\n",
    "    pnb.sweep_args = list(map(get_items(0,2), filter(not_constarg, xargs)))\n",
    "         \n",
    "    return pnb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x', '0'), ('y', '0'), ('task_id', '0'), ('results_dir', '\"./\"'), ('x', '')]\n",
      "[('y', '0'), ('task_id', '0'), ('results_dir', '\"./\"')]\n",
      "[('x', '[0,1,2,3,4]'), ('x', '[0,1,2,3]')]\n",
      "['#nbx\\n', '\\n', '\\n', '\\n', '\\n', '# some comment\\n', 'z = 1', '#nbx\\n', '\\n', 'print(\"some result\")', '#nbx\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "nb  = load_nb(\"om.ipynb\")\n",
    "pnb = parse_nb(nb)\n",
    "print(pnb.args)\n",
    "print(pnb.const_args)\n",
    "print(pnb.sweep_args)\n",
    "print(pnb.func_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the file bundle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_arrays(num, m=1000):\n",
    "    if num < m: return [[1,num]]\n",
    "    \n",
    "    arrays = []\n",
    "    for i in range(num//m): arrays.append([i*m+1, (i+1)*m])\n",
    "    last = arrays[-1][1]\n",
    "    if last < num: arrays.append([last+1, num])\n",
    "        \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1000], [1001, 1543]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_arrays(1543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_job(start, end, step):\n",
    "    return f\"job_0=`sbatch --array={start}-{end}%{step} job.sh | awk '{{ print $4 }}'`\"\n",
    "def cont_job(j, start, end, step):\n",
    "    return f\"job_{j}=`sbatch --array={start}-{end}%{step} --dependency=afterok:$job_{j-1} job.sh | awk '{{ print $4 }}'`\"\n",
    "\n",
    "def chain_jobs(arrays, step):\n",
    "    s = \"\"\n",
    "    for i, arr in enumerate(arrays):\n",
    "        if i ==0: s += init_job(arr[0], arr[1], step)\n",
    "        else: s += cont_job(i, arr[0], arr[1], step)\n",
    "        s += \"\\n\"\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_0=`sbatch --array=1-1000%1 job.sh | awk '{ print $4 }'`\n",
      "job_1=`sbatch --array=1001-1543%1 --dependency=afterok:$job_0 job.sh | awk '{ print $4 }'`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chain_jobs(get_arrays(1543), step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "import pkg_resources\n",
    "import importlib\n",
    "from nbx.templ import *\n",
    "import os\n",
    "\n",
    "def check_parsed_nb(pnb):\n",
    "    keys = list(map(get_item(0), pnb.args))\n",
    "    if \"task_id\" not in keys: raise KeyError(\"You didn't specify `task_id`!!\")\n",
    "    if \"results_dir\" not in keys: raise KeyError(\"You didn't specify `results_dir`!!\")\n",
    "        \n",
    "class NbxBundle():\n",
    "    def __init__(self, \n",
    "                 nbname, \n",
    "                 mail_user,\n",
    "                 name=None, \n",
    "                 linting=True,\n",
    "                 time=[1,0], \n",
    "                 ntasks=10, \n",
    "                 step=5, \n",
    "                 simg=\"pytorch.simg\",\n",
    "                 max_arr=1000,\n",
    "                 mem_per_cpu=2000):\n",
    "\n",
    "        if name is None:\n",
    "            name = Path(nbname).stem\n",
    "            \n",
    "        self.max_arr = max_arr\n",
    "        self.nbname = nbname\n",
    "        self.name = name\n",
    "        self.path = Path(f\"{name}_nbx\")\n",
    "        \n",
    "        nb = load_nb(nbname)\n",
    "        nb = parse_nb(nb)\n",
    "        self.nb = nb\n",
    "        \n",
    "        check_parsed_nb(nb)\n",
    "        \n",
    "        self.create_folders()\n",
    "        self.create_script(\"experiment.tpl\", \"experiment.py\", vars(nb));\n",
    "        \n",
    "\n",
    "        p = \".\".join((self.path/'experiment').parts)\n",
    "        exp =  importlib.import_module(p)\n",
    "        len(exp.sweep_params)        \n",
    "        self.num_configs = len(exp.sweep_params)\n",
    "        \n",
    "        \n",
    "        self.create_run_script(len(exp.sweep_params), step, max_arr)\n",
    "        \n",
    "        self.create_script(\"wrapper.tpl\", \"wrapper.py\", {\n",
    "            'experiment_module': \"experiment\"});\n",
    "        self.create_script(\"job.tpl\", \"job.sh\", {\n",
    "            'job_name': name, \n",
    "            'nbx_folder': os.environ['omx'],\n",
    "            'script_to_run': \"wrapper.py\", \n",
    "            'results_dir': \"./results\",\n",
    "            'hours': time[0],\n",
    "            'mins': time[1],\n",
    "            'ntasks': ntasks,\n",
    "            'script': 'wrapper.py',\n",
    "            'simg': Path(os.environ['omsimg'])/simg, \n",
    "            'mail_user': mail_user, \n",
    "            'mem_per_cpu': mem_per_cpu\n",
    "        });\n",
    "\n",
    "        print(self)\n",
    "        if linting: self.check_scripts()\n",
    "            \n",
    "    def create_run_script(self, num, step, max_arr):\n",
    "        path = self.path/'run.sh'\n",
    "        with open(path, \"w\") as f:\n",
    "            f.write(\"#!/bin/sh\\n\\n\")\n",
    "            f.write(chain_jobs(get_arrays(num, max_arr), step))\n",
    "            \n",
    "    def create_script(self, tname, fname, vars):\n",
    "        tpath = Path(pkg_resources.resource_filename(\n",
    "                     __name__, f\"/templates/{tname}\"))\n",
    "        \n",
    "        create_file_from_template(tpath, \n",
    "            self.path/fname, vars)\n",
    "        \n",
    "        \n",
    "    def create_folders(self):\n",
    "        if not os.path.exists(self.path):\n",
    "            os.makedirs(self.path)\n",
    "            os.makedirs(self.path/'io')\n",
    "\n",
    "        if os.path.exists('./src'):\n",
    "            if not os.path.exists(self.path/'src'):\n",
    "                os.makedirs(self.path/'src')\n",
    "            os.system(f\"cp -r src/* {self.path/'src'}\") \n",
    "\n",
    "        open(self.path/'__init__.py', 'a').close()\n",
    "    \n",
    "                      \n",
    "    def run_experiment(self):\n",
    "        self.run()\n",
    "        print(\"check status with `ssh $om squeue -u $omid` or `bundle.status()`\")\n",
    "        print(\"pull results with `bundle.pull_results()`\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return render_template_from_string(BUNDLE_SUMMARY, \n",
    "                                           vars(self))\n",
    "\n",
    "    def _run_command(self, cmd):\n",
    "        stream = os.popen(cmd)\n",
    "        output = stream.read()\n",
    "        return output.strip()\n",
    "\n",
    "    def push(self):\n",
    "        cmd = f\"scp -r {self.path} $om:$omx\"\n",
    "        output = self._run_command(cmd)\n",
    "        if len(output) > 0:\n",
    "            print(output)\n",
    "\n",
    "    def run(self):\n",
    "        cmd = f\"ssh $om sbatch -D $omx/{self.path} $omx/{self.path}/run.sh\"\n",
    "        print(self._run_command(cmd))\n",
    "                      \n",
    "    def status(self):\n",
    "        cmd = f\"ssh $om squeue -u $omid\"\n",
    "        print(self._run_command(cmd))\n",
    "\n",
    "    def pull_results(self):\n",
    "        cmd = f\"scp -r $om:$omx/{self.path}/results ./{self.path}\"\n",
    "        output = self._run_command(cmd)\n",
    "        if len(output) > 0:\n",
    "            print(output)\n",
    "\n",
    "        print(f\"copied to `{self.path}/results/\")\n",
    "\n",
    "    def check_scripts(self):\n",
    "        output = self._run_command(f\"pylint -E {self.path/'wrapper.py'}\") \n",
    "        if len(output) > 0:\n",
    "            print(output)\n",
    "            raise \"Check wrapper script\"\n",
    "\n",
    "        output = self._run_command(f\"pylint -E {self.path/'experiment.py'}\") \n",
    "        if len(output) > 0:\n",
    "            print(output)\n",
    "            raise \"Check experiment script\"\n",
    "\n",
    "        print(\"(pylinting went ok)\")\n",
    "\n",
    "\n",
    "BUNDLE_SUMMARY = \"\"\"\n",
    "** nbx bundle created **\n",
    "Path:\n",
    "    {{path}}\n",
    "    \n",
    "Source nb:\n",
    "    {{nbname}}\n",
    "\n",
    "Parameters (#configs {{num_configs}}):\n",
    "    {% for k,v in nb.sweep_args %}* {{k}} = {{v}}{% if not loop.last %}\n",
    "    {% endif %}{% endfor %}\n",
    "    {% for k,v in nb.const_args %}  {{k}} = {{v}}{% if not loop.last %}\n",
    "    {% endif %}{% endfor %}\n",
    "\n",
    "Instructions:\n",
    "    Copy to remote, run the bash script, and pull the results\n",
    "    - `bundle.push()` or `scp -r {{path}} $om:$omx` \n",
    "    - `bundle.run()` or `ssh $om sbatch -D $omx/{{path}} $omx/{{path}}/run.sh`\n",
    "    - `bundle.pull_results()` or `scp -r $om:$omx/{{path}}/results ./results`\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
